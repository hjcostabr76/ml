{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic tac toe\n",
    "\n",
    "> Gradient Tree Boosting implementation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    RocCurveDisplay,\n",
    "    precision_recall_curve,\n",
    "    PrecisionRecallDisplay,\n",
    "    f1_score,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_ds = './file/ds_tic-tac-toe.data'\n",
    "\n",
    "# Data parsing parameters\n",
    "class_positive_str, class_negative_str = 'positive', 'negative'\n",
    "classes_names = [class_positive_str, class_negative_str]\n",
    "class_positive, class_negative = 1, 0\n",
    "\n",
    "play_x_str, play_o_str =  'x', 'o'\n",
    "play_x, play_o = 1, 0\n",
    "\n",
    "# Hyper parameters\n",
    "n_folds = 5\n",
    "test_size = .2\n",
    "classes_threshold = .5\n",
    "\n",
    "max_depth = 4\n",
    "max_trees = 10\n",
    "random_state = 10\n",
    "max_features = None\n",
    "learning_rate = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958 samples; Positive cases: 626; Negative cases: 332;\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parse input\n",
    "features = [f'x{i + 1}' for i in range(9)]\n",
    "col_y = 'y'\n",
    "\n",
    "df = pd.read_csv(path_file_ds, header=None)\n",
    "df.columns = features + [col_y]\n",
    "\n",
    "def play_to_number(x: str):\n",
    "    return play_x if x == play_x_str else play_o\n",
    "\n",
    "def class_to_number(y: str):\n",
    "    return class_positive if y == class_positive_str else class_negative\n",
    "\n",
    "# Set working data\n",
    "y = df[col_y].apply(np.vectorize(class_to_number))\n",
    "X = df[features].apply(np.vectorize(play_to_number))\n",
    "\n",
    "# See what we've got\n",
    "n = len(y)\n",
    "n_positive = np.sum(y == class_positive)\n",
    "n_negative = np.sum(y == class_negative)\n",
    "\n",
    "print(f\"{n} samples; Positive cases: {n_positive}; Negative cases: {n_negative};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientTreeBoosting():\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        max_depth: int = 4,\n",
    "        max_trees: int = 10,\n",
    "        max_features: int = None,\n",
    "        learning_rate: float = 0.4,\n",
    "        random_state: int = 0\n",
    "    ):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.max_trees = max_trees\n",
    "        self.max_features = max_features\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self._weak_learners = []\n",
    "        self._predictions = np.array([])\n",
    "        self._random_state = random_state\n",
    "        \n",
    "\n",
    "    def fit(self, y: np.array, X: np.array):\n",
    "\n",
    "        n = len(y)\n",
    "        predictions = np.array([y.mean()] * n)\n",
    "\n",
    "        for _ in range(self.max_trees):\n",
    "\n",
    "            # Creating a weak learner \n",
    "            weak_learner = tree.DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                max_features=self.max_features,\n",
    "                random_state=self._random_state,\n",
    "            )\n",
    "\n",
    "            # Growing the tree on the residuals\n",
    "            residuals = y - predictions\n",
    "            weak_learner.fit(X, residuals)\n",
    "            self._weak_learners.append(weak_learner)\n",
    "\n",
    "            # Updating predictions\n",
    "            predictions_wl = weak_learner.predict(X)\n",
    "            predictions += self.learning_rate * predictions_wl\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        n = len(X)\n",
    "        yHat = np.zeros( (n,) )\n",
    "        for weak_learner in self._weak_learners:\n",
    "            yHat += self.learning_rate * weak_learner.predict(X)\n",
    "        return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31855/670258325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mclasses_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31855/2954931038.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, X)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# Growing the tree on the residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mresiduals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mweak_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresiduals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weak_learners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_learner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     ]:\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "classifier = GradientTreeBoosting(\n",
    "    max_depth=max_depth,\n",
    "    max_trees=max_trees,\n",
    "    max_features=max_features,\n",
    "    learning_rate=learning_rate,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=n_folds, test_size=test_size, random_state=random_state)\n",
    "\n",
    "recalls = np.array([])\n",
    "accuracies = np.array([])\n",
    "precisions = np.array([])\n",
    "f1_scores_pos = np.array([])\n",
    "f1_scores_neg = np.array([])\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    \n",
    "    # Train & test\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    n_test, n_train = len(test_index), len(train_index)\n",
    "\n",
    "    classifier.fit(X=X_train, y=y_train)\n",
    "    outputs = classifier.predict(X=X_test)\n",
    "    y_hat = (outputs > classes_threshold).astype(int)\n",
    "\n",
    "    # Evaluate\n",
    "    accuracy = np.sum(y_hat == y_test) / n\n",
    "    f1_pos, f1_neg = f1_score(y_test, y_hat, average=None)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, outputs, pos_label=1)\n",
    "\n",
    "    # Display summary\n",
    "    print('-' * 30)\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(r\"Train Samples: %d; Test Samples: %d\" % (n_train, n_test))\n",
    "    print(r\"Accuracy: %.4f\" % accuracy)\n",
    "    print(r\"Precision (average): %.4f\" % precision.mean())\n",
    "    print(r\"Recall (average): %.4f\" % recall.mean())\n",
    "    print(r\"F1 Score (positive): %.4f\" % f1_pos)\n",
    "    print(r\"F1 Score (negative): %.4f\" % f1_neg)\n",
    "    print('')\n",
    "\n",
    "    # Display confusion Matrix\n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(16, 6))\n",
    "    conf_matrix = confusion_matrix(y_test, y_hat)\n",
    "    display_conf_matrix = ConfusionMatrixDisplay(conf_matrix)\n",
    "\n",
    "    plt.title(f'Confusion Matrix - Iteration {i + 1}', fontsize=22)\n",
    "    plt.xticks(range(2), classes_names, fontsize=10)\n",
    "    plt.yticks(range(2), classes_names, fontsize=10)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.ylabel('Real', fontsize=12)\n",
    "    display_conf_matrix.plot(ax=ax1)\n",
    "    plt.show()\n",
    "    print('')\n",
    "\n",
    "    # Display ROC Curve\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, outputs, pos_label=1)\n",
    "    display_roc = RocCurveDisplay(fpr=fpr, tpr=tpr)\n",
    "    ax1.set_title(f'ROC Curve - Iteration {i + 1}', fontsize=22)\n",
    "    display_roc.plot(ax=ax1)\n",
    "\n",
    "    # Display Precision x Recall Curve\n",
    "    display_precision_recall = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "    ax2.set_title(f'Precision vs. Recall Curve - Iteration {i + 1}', fontsize=22)\n",
    "    display_precision_recall.plot(ax=ax2)\n",
    "    plt.show()\n",
    "\n",
    "    # Compute this fold\n",
    "    recalls = np.append(recalls, recall)\n",
    "    accuracies = np.append(accuracies, accuracy)\n",
    "    precisions = np.append(precisions, precision)\n",
    "    f1_scores_pos = np.append(f1_scores_pos, f1_pos)\n",
    "    f1_scores_neg = np.append(f1_scores_neg, f1_neg)\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
