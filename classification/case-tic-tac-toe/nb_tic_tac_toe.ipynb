{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tic tac toe\n",
    "\n",
    "> Gradient Tree Boosting implementation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from sklearn import preprocessing, model_selection, naive_bayes, tree, svm, neighbors, ensemble\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file_ds = './file/ds_tic-tac-toe.data'\n",
    "\n",
    "# Data parsing parameters\n",
    "class_positive_str, class_negative_str = 'positive', 'negative'\n",
    "class_positive, class_negative = 1, 0\n",
    "\n",
    "play_x_str, play_o_str =  'x', 'o'\n",
    "play_x, play_o = 1, -1\n",
    "\n",
    "# Hyper parameters\n",
    "max_depth = 4\n",
    "max_trees = 10\n",
    "random_state = 10\n",
    "max_features = None\n",
    "learning_rate = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958 samples: 626 positive cases; 332 negative cases\n"
     ]
    }
   ],
   "source": [
    "features = [f'x{i + 1}' for i in range(9)]\n",
    "col_y = 'y'\n",
    "\n",
    "df = pd.read_csv(path_file_ds, header=None)\n",
    "df.columns = features + [col_y]\n",
    "\n",
    "def play_to_number(x: str):\n",
    "    return play_x if x == play_x_str else play_o\n",
    "\n",
    "def class_to_number(y: str):\n",
    "    return class_positive if y == class_positive_str else class_negative\n",
    "\n",
    "y = ds[col_y].apply(np.vectorize(class_to_number))\n",
    "X = ds[features].apply(np.vectorize(play_to_number))\n",
    "\n",
    "n = len(y)\n",
    "n_positive = np.sum(y == class_positive)\n",
    "n_negative = np.sum(y == class_negative)\n",
    "\n",
    "print(f\"{n} samples: {n_positive} positive cases; {n_negative} negative cases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Tree Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientTreeBoosting():\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        max_depth: int = 4,\n",
    "        max_trees: int = 10,\n",
    "        max_features: int = None,\n",
    "        learning_rate: float = 0.4,\n",
    "        random_state: int = 0\n",
    "    ):\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.max_trees = max_trees\n",
    "        self.max_features = max_features\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self._weak_learners = []\n",
    "        self._predictions = np.array([])\n",
    "        self._random_state = random_state\n",
    "        \n",
    "\n",
    "    def fit(self, y: np.array, X: np.array):\n",
    "\n",
    "        n = len(y)\n",
    "        predictions = np.array([y.mean()] * n)\n",
    "\n",
    "        for _ in range(self.max_trees):\n",
    "\n",
    "            # Creating a weak learner \n",
    "            weak_learner = tree.DecisionTreeRegressor(\n",
    "                max_depth=self.max_depth,\n",
    "                max_features=self.max_features,\n",
    "                random_state=self._random_state,\n",
    "            )\n",
    "\n",
    "            # Growing the tree on the residuals\n",
    "            residuals = y - predictions\n",
    "            weak_learner.fit(X, residuals)\n",
    "            self._weak_learners.append(weak_learner)\n",
    "\n",
    "            # Updating predictions\n",
    "            predictions_wl = weak_learner.predict(X)\n",
    "            predictions += self.learning_rate * predictions_wl\n",
    "\n",
    "    def predict(self, X: np.array) -> np.array:\n",
    "        n = len(X)\n",
    "        yHat = np.zeros( (n,) )\n",
    "        for weak_learner in self._weak_learners:\n",
    "            yHat += self.learning_rate * weak_learner.predict(X)\n",
    "        return yHat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pos: 620, n_neg: 338\n"
     ]
    }
   ],
   "source": [
    "classifier = GradientTreeBoosting(\n",
    "    max_depth=max_depth,\n",
    "    max_trees=max_trees,\n",
    "    max_features=max_features,\n",
    "    learning_rate=learning_rate,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "classifier.fit(X=X.values, y=y.values)\n",
    "yHat = classifier.predict(X=X.values)\n",
    "\n",
    "n_pos = np.sum(yHat > 0)\n",
    "n_neg = n - n_pos\n",
    "print(f\"n_pos: {n_pos}, n_neg: {n_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = classifier.predict(X=X.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
